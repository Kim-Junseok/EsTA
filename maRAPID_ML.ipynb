{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN approach for maRAPID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodsol Lee, Netlab, Seoul National University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import os\n",
    "\n",
    "#configuration for gpu usage\n",
    "conf = tf.ConfigProto()\n",
    "# you can modify below as you want\n",
    "#conf.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "#conf.gpu_options.allow_growth = True\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Sample training data, validation data, test data from raw data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19456,
     "status": "ok",
     "timestamp": 1449847956073,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "0ddb1607-1fc4-4ddb-de28-6c7ab7fb0c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get sample from node1\n",
      "25678\n",
      "Get sample from node2\n",
      "15553\n",
      "Get sample from node3\n",
      "25285\n",
      "Get sample from node4\n",
      "18552\n",
      "Get sample from node5\n",
      "26527\n",
      "Get sample from node6\n",
      "21138\n",
      "Get sample from node7\n",
      "30513\n",
      "Get sample from node8\n",
      "52905\n",
      "Get sample from node9\n",
      "26551\n",
      "Get sample from node10\n",
      "21704\n",
      "Get sample from node11\n",
      "21477\n",
      "Get sample from node12\n",
      "16702\n",
      "Get sample from node13\n",
      "33326\n",
      "Get sample from node14\n",
      "23333\n",
      "Get sample from node15\n",
      "52102\n",
      "Get sample from node16\n",
      "34728\n",
      "Get sample from node17\n",
      "26327\n",
      "Get sample from node18\n",
      "29110\n",
      "Get sample from node19\n",
      "22327\n",
      "Get sample from node20\n",
      "24527\n",
      "Get sample from node21\n",
      "41902\n",
      "Get sample from node22\n",
      "40852\n",
      "Get sample from node23\n",
      "11776\n",
      "Get sample from node24\n",
      "23927\n",
      "Get sample from node25\n",
      "27926\n",
      "Get sample from node26\n",
      "42306\n",
      "Get sample from node27\n",
      "29327\n",
      "Get sample from node28\n",
      "20752\n",
      "Get sample from node29\n",
      "24151\n",
      "Get sample from node30\n",
      "25154\n",
      "Get sample from node31\n",
      "35131\n",
      "Get sample from node32\n",
      "34127\n",
      "Get sample from node33\n",
      "25151\n",
      "Get sample from node34\n",
      "20526\n",
      "Get sample from node35\n",
      "17727\n",
      "Get sample from node36\n",
      "29127\n",
      "Get sample from node37\n",
      "22161\n",
      "Get sample from node38\n",
      "9375\n",
      "Get sample from node39\n",
      "24509\n",
      "Get sample from node40\n",
      "20552\n",
      "Get sample from node41\n",
      "17551\n",
      "Get sample from node42\n",
      "22951\n",
      "Get sample from node43\n",
      "15894\n",
      "Get sample from node44\n",
      "22727\n",
      "Get sample from node45\n",
      "35454\n",
      "Get sample from node46\n",
      "38129\n",
      "Get sample from node47\n",
      "27327\n",
      "Get sample from node48\n",
      "32327\n",
      "Get sample from node49\n",
      "20745\n",
      "Get sample from node50\n",
      "14351\n",
      "Get sample from node51\n",
      "41353\n",
      "Get sample from node52\n",
      "27877\n",
      "Get sample from node53\n",
      "14751\n",
      "Get sample from node54\n",
      "26326\n",
      "Get sample from node55\n",
      "27352\n",
      "Get sample from node56\n",
      "21751\n",
      "Get sample from node57\n",
      "41308\n",
      "Get sample from node58\n",
      "27114\n",
      "Get sample from node59\n",
      "23926\n",
      "Get sample from node60\n",
      "27877\n",
      "Get sample from node61\n",
      "23551\n",
      "Get sample from node62\n",
      "25752\n",
      "Get sample from node63\n",
      "34917\n",
      "Get sample from node64\n",
      "27327\n",
      "Get sample from node65\n",
      "19552\n",
      "Get sample from node66\n",
      "23352\n",
      "Get sample from node67\n",
      "39652\n",
      "Get sample from node68\n",
      "11377\n",
      "Get sample from node69\n",
      "20905\n",
      "Get sample from node70\n",
      "27526\n",
      "Get sample from node71\n",
      "25127\n",
      "Get sample from node72\n",
      "18527\n",
      "Get sample from node73\n",
      "22127\n",
      "Get sample from node74\n",
      "35902\n",
      "Get sample from node75\n",
      "30502\n",
      "Get sample from node76\n",
      "16151\n",
      "Get sample from node77\n",
      "23751\n",
      "Get sample from node78\n",
      "26102\n",
      "Get sample from node79\n",
      "43702\n",
      "Get sample from node80\n",
      "38127\n",
      "Get sample from node81\n",
      "46852\n",
      "Get sample from node82\n",
      "27951\n",
      "Get sample from node83\n",
      "20523\n",
      "Get sample from node84\n",
      "28957\n",
      "Get sample from node85\n",
      "44710\n",
      "Get sample from node86\n",
      "22551\n",
      "Get sample from node87\n",
      "41530\n",
      "Get sample from node88\n",
      "26909\n",
      "Get sample from node89\n",
      "22852\n",
      "Get sample from node90\n",
      "10977\n",
      "Get sample from node91\n",
      "18776\n",
      "Get sample from node92\n",
      "17552\n",
      "Get sample from node93\n",
      "37527\n",
      "Get sample from node94\n",
      "33877\n",
      "Get sample from node95\n",
      "28332\n",
      "Get sample from node96\n",
      "25527\n",
      "Get sample from node97\n",
      "19552\n",
      "Get sample from node98\n",
      "40757\n",
      "Get sample from node99\n",
      "17759\n",
      "Get sample from node100\n",
      "10927\n",
      "Get sample from node101\n",
      "18085\n",
      "Get sample from node102\n",
      "11551\n",
      "Get sample from node103\n",
      "27327\n",
      "Get sample from node104\n",
      "19534\n",
      "Get sample from node105\n",
      "21753\n",
      "Get sample from node106\n",
      "10327\n",
      "Get sample from node107\n",
      "33551\n",
      "Get sample from node108\n",
      "32713\n",
      "Get sample from node109\n",
      "44702\n",
      "Get sample from node110\n",
      "24527\n",
      "Get sample from node111\n",
      "22152\n",
      "Get sample from node112\n",
      "42052\n",
      "Get sample from node113\n",
      "7192\n",
      "Get sample from node114\n",
      "16952\n",
      "Get sample from node115\n",
      "27102\n",
      "Get sample from node116\n",
      "39477\n",
      "Get sample from node117\n",
      "29527\n",
      "Get sample from node118\n",
      "25476\n",
      "Get sample from node119\n",
      "17151\n",
      "Get sample from node120\n",
      "35502\n",
      "Get sample from node121\n",
      "42876\n",
      "Get sample from node122\n",
      "35527\n",
      "Get sample from node123\n",
      "19152\n",
      "Get sample from node124\n",
      "31102\n",
      "Get sample from node125\n",
      "37106\n",
      "Get sample from node126\n",
      "34102\n",
      "Get sample from node127\n",
      "43852\n",
      "Get sample from node128\n",
      "24747\n",
      "Get sample from node129\n",
      "42928\n",
      "Get sample from node130\n",
      "27103\n",
      "Get sample from node131\n",
      "26127\n",
      "Get sample from node132\n",
      "23152\n",
      "Get sample from node133\n",
      "19927\n",
      "Get sample from node134\n",
      "18551\n",
      "Get sample from node135\n",
      "28527\n",
      "Get sample from node136\n",
      "27335\n",
      "Get sample from node137\n",
      "32534\n",
      "Get sample from node138\n",
      "14745\n",
      "Get sample from node139\n",
      "11152\n",
      "Get sample from node140\n",
      "30526\n",
      "Get sample from node141\n",
      "42727\n",
      "Get sample from node142\n",
      "13952\n",
      "Get sample from node143\n",
      "18102\n",
      "Get sample from node144\n",
      "38737\n",
      "Get sample from node145\n",
      "12127\n",
      "Get sample from node146\n",
      "17076\n",
      "Get sample from node147\n",
      "21952\n",
      "Get sample from node148\n",
      "22127\n",
      "Get sample from node149\n",
      "28526\n",
      "Get sample from node150\n",
      "25301\n",
      "Get sample from node151\n",
      "19326\n",
      "Get sample from node152\n",
      "13151\n",
      "Get sample from node153\n",
      "13126\n",
      "Get sample from node154\n",
      "7151\n",
      "Get sample from node155\n",
      "976\n",
      "Sampling is completed, sample length:  4052323\n"
     ]
    }
   ],
   "source": [
    "node_num = 155\n",
    "num_RSSI_sample = 25\n",
    "\n",
    "data_set = np.empty((num_RSSI_sample))\n",
    "channel_label_set = np.empty((1))\n",
    "TA_label_set = np.empty((1))\n",
    "\n",
    "for node_index in range(1,node_num+1):\n",
    "    print('Get sample from node'+str(node_index))\n",
    "    file_name = 'data/node-'+str(node_index)+'.txt'\n",
    "    previous_cellId = -1\n",
    "    cell_sample = list()\n",
    "    cell_sample_set = list()\n",
    "    \n",
    "    with open(file_name, 'r') as f:\n",
    "        while 1:\n",
    "            line = f.readline()\n",
    "            if not line: break\n",
    "            parsed_line =line.split(' ')\n",
    "            \n",
    "            rssi = parsed_line[9]\n",
    "            channel_state = parsed_line[8]\n",
    "            current_cellId = parsed_line[10]\n",
    "            TA_region = parsed_line[11]\n",
    "            \n",
    "            if previous_cellId == current_cellId:\n",
    "                cell_sample.append([rssi, channel_state, TA_region])\n",
    "            else:\n",
    "                previous_cellId = current_cellId\n",
    "                if cell_sample:\n",
    "                    cell_sample_set.append(cell_sample)\n",
    "                    cell_sample = list()\n",
    "        \n",
    "        cell_sample_set.append(cell_sample)\n",
    "        sample_length = 0\n",
    "        for i in range(len(cell_sample_set)):\n",
    "            sample_length += len(cell_sample_set[i])-num_RSSI_sample+1\n",
    "        \n",
    "        print(sample_length)\n",
    "        \n",
    "        temp_data_set = np.zeros((sample_length,num_RSSI_sample))\n",
    "        temp_channel_label_set = np.zeros((sample_length,1))\n",
    "        temp_TA_label_set = np.zeros((sample_length,1))\n",
    "        \n",
    "        for i in range(len(cell_sample_set)):\n",
    "            cell_sample = cell_sample_set[i]\n",
    "            cell_sample = np.array(cell_sample)\n",
    "            for j in range(len(cell_sample_set[i])-num_RSSI_sample+1):\n",
    "                temp_data_set[j] = cell_sample[j:j+num_RSSI_sample,0]\n",
    "                temp_channel_label_set[j] = cell_sample[j+num_RSSI_sample-1,1]\n",
    "                temp_TA_label_set[j] = cell_sample[j+num_RSSI_sample-1,2] \n",
    "              \n",
    "    if node_index == 1:\n",
    "        data_set = temp_data_set\n",
    "        channel_label_set = temp_channel_label_set\n",
    "        TA_label_set = temp_TA_label_set\n",
    "    else:\n",
    "        data_set = np.append(data_set,temp_data_set,axis = 0)\n",
    "        channel_label_set = np.append(channel_label_set,temp_channel_label_set,axis = 0)\n",
    "        TA_label_set = np.append(TA_label_set,temp_TA_label_set,axis=0)\n",
    "    \n",
    "print('Sampling is completed, sample length: ',data_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meme\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print('me'+'me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "data_length = data_set.shape[0]\n",
    "valid_num = 100000\n",
    "test_num = 100000\n",
    "\n",
    "#get test set\n",
    "test_index = random.sample(range(0,data_length-test_num),test_num)\n",
    "test_data = data_set[test_index]\n",
    "test_channel_label = channel_label_set[test_index]\n",
    "test_TA_label = TA_label_set[test_index]\n",
    "\n",
    "#get training set/validation set\n",
    "train_data_set = np.delete(data_set,test_index,axis=0)\n",
    "train_channel_label_set = np.delete(channel_label_set,test_index,axis=0)\n",
    "train_TA_label_set = np.delete(TA_label_set,test_index,axis=0)\n",
    "data_length = train_data_set.shape[0]\n",
    "\n",
    "valid_index = random.sample(range(0,data_length),valid_num)\n",
    "\n",
    "training_data = train_data_set\n",
    "training_channel_label = train_channel_label_set\n",
    "training_TA_label = train_TA_label_set\n",
    "\n",
    "valid_data = train_data_set[valid_index]\n",
    "valid_channel_label = train_channel_label_set[valid_index]\n",
    "valid_TA_label = train_TA_label_set[valid_index]\n",
    "\n",
    "save_data ={\n",
    "    'training_data':training_data,\n",
    "    'training_channel_label':training_channel_label,\n",
    "    'training_TA_label':training_TA_label,\n",
    "    \n",
    "    'valid_data':valid_data,\n",
    "    'valid_channel_label':valid_channel_label,\n",
    "    'valid_TA_label':valid_TA_label,\n",
    "    \n",
    "    'test_data':test_data,\n",
    "    'test_channel_label':test_channel_label,\n",
    "    'test_TA_label':test_TA_label\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get name of the data path\n",
    "data_path = 'data/save_data'+str(num_RSSI_sample)+'.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "with open(data_path,'wb') as f:\n",
    "    pickle.dump(save_data,f,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (3952323, 25) (3952323, 1)\n",
      "Validation set (100000, 25) (100000, 1)\n",
      "Test set (100000, 25) (100000, 1)\n"
     ]
    }
   ],
   "source": [
    "# restore data\n",
    "with open(data_path,'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    \n",
    "    train_dataset = save['training_data']\n",
    "    train_channel_labels = save['training_channel_label']\n",
    "    train_labels = save['training_TA_label']\n",
    "    \n",
    "    valid_dataset = save['valid_data']\n",
    "    valid_channel_labels = save['valid_channel_label']\n",
    "    valid_labels = save['valid_TA_label']\n",
    "    \n",
    "    test_dataset = save['test_data']\n",
    "    test_channel_labels = save['test_channel_label']\n",
    "    test_labels = save['test_TA_label']\n",
    "    \n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gslee/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (3952323, 25) (3952323, 4)\n",
      "Validation set (100000, 25) (100000, 4)\n",
      "Test set (100000, 25) (100000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gslee/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/gslee/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, num_RSSI_sample)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    enc.fit(labels)\n",
    "    labels = enc.transform(labels).toarray()\n",
    "    return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = num_RSSI_sample\n",
    "num_labels = 4\n",
    "\n",
    "layer1_output_num = 200\n",
    "layer2_output_num = 200\n",
    "layer3_output_num = 200\n",
    "layer4_output_num = 512\n",
    "layer5_output_num = 256\n",
    "num_steps = 1000\n",
    "batch_size = 100000\n",
    "\n",
    "graph_gs=tf.Graph()\n",
    "with graph_gs.as_default():\n",
    "    tf_dataset_gs=tf.placeholder(tf.float32, shape=(None, sample_size))\n",
    "    tf_labels_gs=tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "    keep_prob = tf.placeholder(tf.float32, shape=(None))\n",
    "    is_train = tf.placeholder(tf.bool)\n",
    "    \n",
    "    lambda_reg = 0.000000000001\n",
    "        \n",
    "    #Regularization\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=lambda_reg)\n",
    "    initializer = tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)\n",
    "    #neural network consists of two lines\n",
    "    dense1 = tf.layers.dense(tf_dataset_gs, layer1_output_num, activation=tf.nn.relu, kernel_regularizer=regularizer)\n",
    "    dense1 = tf.nn.dropout(dense1, keep_prob = keep_prob)\n",
    "    dense1 = tf.layers.batch_normalization(dense1, training=is_train)\n",
    "    \n",
    "    dense2 = tf.layers.dense(dense1,layer2_output_num, activation=tf.nn.relu, kernel_regularizer=regularizer)\n",
    "    dense2 = tf.nn.dropout(dense2, keep_prob = keep_prob)\n",
    "    dense2 = tf.layers.batch_normalization(dense2, training=is_train)\n",
    "    \n",
    "    dense3 = tf.layers.dense(dense2 ,layer3_output_num, activation=tf.nn.relu, kernel_regularizer=regularizer)\n",
    "    dense3 = tf.nn.dropout(dense3, keep_prob = keep_prob)\n",
    "    dense3 = tf.layers.batch_normalization(dense3, training=is_train)\n",
    "    \n",
    "    dense4 = tf.layers.dense(dense3 ,layer4_output_num, activation=tf.nn.relu, kernel_regularizer=regularizer)\n",
    "    dense4 = tf.nn.dropout(dense4, keep_prob = keep_prob)\n",
    "    dense4 = tf.layers.batch_normalization(dense4, training=is_train)\n",
    "    \n",
    "    dense5 = tf.layers.dense(dense4 ,layer4_output_num, activation=tf.nn.relu, kernel_regularizer=regularizer)\n",
    "    dense5 = tf.nn.dropout(dense5, keep_prob = keep_prob)\n",
    "    dense5 = tf.layers.batch_normalization(dense5, training=is_train)\n",
    "    logits_gs = tf.layers.dense(dense2, num_labels, activation=None)\n",
    "    \n",
    "    #Loss\n",
    "    loss_gs = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_labels_gs, logits=logits_gs))\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.005\n",
    "    \n",
    "    decay_num =  50*(int)(train_labels.shape[0]/batch_size)\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, decay_num, 1, staircase=True)\n",
    "    # Optimizer\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizer_gs = tf.train.AdamOptimizer(learning_rate).minimize(loss_gs, global_step=global_step)\n",
    "    \n",
    "    #Predictions for the training\n",
    "    prediction_gs = tf.nn.softmax(logits_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 20.447573\n",
      "Validation accuracy: 62.1%\n",
      "Minibatch loss at step 1: 9.152813\n",
      "Validation accuracy: 62.1%\n",
      "Minibatch loss at step 2: 8.953965\n",
      "Validation accuracy: 62.1%\n",
      "Minibatch loss at step 3: 8.943863\n",
      "Validation accuracy: 62.1%\n",
      "Minibatch loss at step 4: 8.921030\n",
      "Validation accuracy: 62.7%\n",
      "Minibatch loss at step 5: 8.936125\n",
      "Validation accuracy: 64.1%\n",
      "Minibatch loss at step 6: 8.912061\n",
      "Validation accuracy: 67.3%\n",
      "Minibatch loss at step 7: 8.907360\n",
      "Validation accuracy: 69.9%\n",
      "Minibatch loss at step 8: 8.906238\n",
      "Validation accuracy: 71.2%\n",
      "Minibatch loss at step 9: 8.902484\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 10: 8.913095\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 11: 8.912536\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 12: 8.914952\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 13: 8.896912\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 14: 8.899108\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 15: 8.896188\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 16: 8.908548\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 17: 8.909116\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 18: 8.920954\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 19: 8.907035\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 20: 8.907254\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 21: 8.907033\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 22: 8.915908\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 23: 8.907956\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 24: 8.907438\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss at step 25: 8.918193\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 26: 8.897678\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 27: 8.921642\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 28: 8.908128\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29: 8.910606\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 30: 8.930647\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 31: 8.896672\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss at step 32: 8.904123\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 33: 8.907635\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 34: 8.899122\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 35: 8.894426\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 36: 8.896549\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 37: 8.899845\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 38: 8.894428\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 39: 8.914797\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 40: 8.906456\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 41: 8.904790\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 42: 8.907234\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 43: 8.915947\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 44: 8.896646\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 45: 8.904407\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 46: 8.905865\n",
      "Validation accuracy: 82.7%\n",
      "Minibatch loss at step 47: 8.911362\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 48: 8.907528\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 49: 8.918114\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 50: 8.897063\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 51: 8.910681\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 52: 8.921847\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 53: 8.896441\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 54: 8.895233\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 55: 8.917316\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 56: 8.921937\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 57: 8.907739\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 58: 8.904270\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 59: 8.895699\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 60: 8.882217\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 61: 8.891229\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 62: 8.890552\n",
      "Validation accuracy: 82.9%\n",
      "Minibatch loss at step 63: 8.901924\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 64: 8.883028\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 65: 8.892645\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 66: 8.896801\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 67: 8.894594\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 68: 8.884838\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 69: 8.885812\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 70: 8.903243\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 71: 8.889381\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 72: 8.887705\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 73: 8.881476\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 74: 8.899842\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 75: 8.907532\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 76: 8.900704\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 77: 8.882254\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 78: 8.879435\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 79: 8.879601\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 80: 8.889677\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 81: 8.897076\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 82: 8.892654\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 83: 8.886898\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 84: 8.872224\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 85: 8.891146\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 86: 8.873492\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 87: 8.891840\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 88: 8.886507\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 89: 8.880688\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 90: 8.873409\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 91: 8.889061\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 92: 8.904691\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 93: 8.872239\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 94: 8.881581\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 95: 8.897521\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 96: 8.890869\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 97: 8.890209\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 98: 8.880895\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 99: 8.874043\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 100: 8.880750\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 101: 8.885688\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 102: 8.882946\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 103: 8.873153\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 104: 8.881266\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 105: 8.907055\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 106: 8.907971\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 107: 8.887562\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 108: 8.872793\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 109: 8.895104\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 110: 8.891750\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss at step 111: 8.896664\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 112: 8.908487\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 113: 8.874838\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 114: 8.871933\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 115: 8.876691\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 116: 8.877132\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 117: 8.872666\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 118: 8.865295\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 119: 8.896406\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 120: 8.888952\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 121: 8.869216\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 122: 8.888896\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 123: 8.869886\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 124: 8.883404\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 125: 8.877928\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 126: 8.874219\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 127: 8.899313\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 128: 8.878720\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 129: 8.920066\n",
      "Validation accuracy: 85.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 130: 8.894848\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 131: 8.885290\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 132: 8.884370\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 133: 8.870096\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 134: 8.880593\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 135: 8.901769\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 136: 8.882572\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 137: 8.884258\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 138: 8.879420\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 139: 8.878533\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 140: 8.886680\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 141: 8.880703\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 142: 8.885815\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 143: 8.870768\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 144: 8.878618\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 145: 8.874808\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 146: 8.888956\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 147: 8.877608\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 148: 8.876605\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 149: 8.878230\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 150: 8.890515\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 151: 8.896254\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 152: 8.879760\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 153: 8.880713\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 154: 8.902848\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 155: 8.896630\n",
      "Validation accuracy: 82.7%\n",
      "Minibatch loss at step 156: 8.891445\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 157: 8.876853\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 158: 8.872270\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 159: 8.871821\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 160: 8.888570\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 161: 8.873205\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 162: 8.876218\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 163: 8.880384\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 164: 8.880343\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 165: 8.874858\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 166: 8.885475\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 167: 8.887530\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 168: 8.907864\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 169: 8.874306\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 170: 8.874751\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 171: 8.877234\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 172: 8.881262\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 173: 8.882675\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 174: 8.875790\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 175: 8.876093\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 176: 8.878096\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 177: 8.892247\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 178: 8.886831\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 179: 8.891504\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 180: 8.899133\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 181: 8.884054\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 182: 8.871455\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 183: 8.874378\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 184: 8.878048\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 185: 8.888224\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 186: 8.871418\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 187: 8.877326\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 188: 8.872199\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 189: 8.879294\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 190: 8.871114\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 191: 8.886895\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 192: 8.875645\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 193: 8.890907\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 194: 8.880967\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 195: 8.884986\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 196: 8.874317\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 197: 8.874268\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 198: 8.873820\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 199: 8.881235\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 200: 8.874704\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 201: 8.879367\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 202: 8.881172\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 203: 8.874547\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 204: 8.880319\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 205: 8.870042\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 206: 8.872581\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 207: 8.872394\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 208: 8.890078\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 209: 8.901984\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 210: 8.880722\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 211: 8.876461\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 212: 8.883862\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 213: 8.869558\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 214: 8.871792\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 215: 8.876666\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 216: 8.880698\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 217: 8.877097\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 218: 8.871037\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 219: 8.874385\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 220: 8.889649\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 221: 8.874149\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 222: 8.876132\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 223: 8.884468\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 224: 8.867897\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 225: 8.871723\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 226: 8.873538\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 227: 8.873777\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 228: 8.880084\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 229: 8.863322\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 230: 8.877088\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 231: 8.891732\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 232: 8.882524\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 233: 8.868707\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 234: 8.873294\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 235: 8.874235\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 236: 8.882544\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 237: 8.907750\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 238: 8.895452\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 239: 8.879534\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 240: 8.876946\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 241: 8.874097\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 242: 8.868880\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 243: 8.877717\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 244: 8.869321\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 245: 8.873192\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 246: 8.876292\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 247: 8.880908\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 248: 8.880060\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 249: 8.870711\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 250: 8.881019\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 251: 8.876643\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 252: 8.878261\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 253: 8.868316\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 254: 8.887845\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 255: 8.871572\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 256: 8.875949\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 257: 8.879722\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 258: 8.870417\n",
      "Validation accuracy: 86.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 259: 8.881953\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 260: 8.873760\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 261: 8.874078\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 262: 8.882549\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 263: 8.874812\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 264: 8.896572\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 265: 8.908630\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 266: 8.878272\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 267: 8.869312\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 268: 8.883948\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 269: 8.884913\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 270: 8.874199\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 271: 8.867555\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 272: 8.874266\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 273: 8.876756\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 274: 8.877715\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 275: 8.866468\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 276: 8.871212\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 277: 8.869710\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 278: 8.876123\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 279: 8.876251\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 280: 8.875801\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 281: 8.870328\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 282: 8.880333\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 283: 8.866915\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 284: 8.870090\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 285: 8.875327\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 286: 8.884085\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 287: 8.875560\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 288: 8.872379\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 289: 8.872102\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 290: 8.871699\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 291: 8.872314\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 292: 8.874434\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 293: 8.879110\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 294: 8.871788\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 295: 8.870123\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 296: 8.868496\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 297: 8.881512\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 298: 8.867891\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 299: 8.876066\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 300: 8.884672\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 301: 8.876840\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 302: 8.875159\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 303: 8.875623\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 304: 8.871612\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 305: 8.868781\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 306: 8.881740\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 307: 8.871031\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 308: 8.871704\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 309: 8.876171\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 310: 8.875774\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 311: 8.868296\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 312: 8.868291\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 313: 8.875589\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 314: 8.875956\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 315: 8.868742\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 316: 8.867727\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 317: 8.873477\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 318: 8.875464\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 319: 8.871174\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 320: 8.876513\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 321: 8.872665\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 322: 8.873350\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 323: 8.872999\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 324: 8.876343\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 325: 8.878791\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 326: 8.866409\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 327: 8.872869\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 328: 8.870320\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 329: 8.882395\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 330: 8.866679\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 331: 8.876282\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 332: 8.878234\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 333: 8.877936\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 334: 8.868446\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 335: 8.864444\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 336: 8.862166\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 337: 8.866966\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 338: 8.874506\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 339: 8.870164\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 340: 8.885058\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 341: 8.876428\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 342: 8.869384\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 343: 8.882879\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 344: 8.867793\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 345: 8.880092\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 346: 8.868094\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 347: 8.864645\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 348: 8.873867\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 349: 8.872205\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 350: 8.879824\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 351: 8.879733\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 352: 8.873663\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 353: 8.868251\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 354: 8.868717\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 355: 8.867683\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 356: 8.872221\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 357: 8.868787\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 358: 8.878314\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 359: 8.872402\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 360: 8.861746\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 361: 8.875559\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 362: 8.871231\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 363: 8.885446\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 364: 8.880848\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 365: 8.866219\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 366: 8.876011\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 367: 8.870168\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 368: 8.869158\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 369: 8.876101\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 370: 8.867429\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 371: 8.871343\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 372: 8.875653\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 373: 8.872385\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 374: 8.877830\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 375: 8.874984\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 376: 8.873490\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 377: 8.868225\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 378: 8.870783\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 379: 8.892590\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 380: 8.876557\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 381: 8.869159\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 382: 8.866781\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 383: 8.862417\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 384: 8.864609\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 385: 8.867548\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 386: 8.870781\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 387: 8.869057\n",
      "Validation accuracy: 87.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 388: 8.876658\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 389: 8.863392\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 390: 8.866917\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 391: 8.865075\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 392: 8.874100\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 393: 8.877015\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 394: 8.863924\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 395: 8.863243\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 396: 8.861362\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 397: 8.874074\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 398: 8.867092\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 399: 8.881968\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 400: 8.877333\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 401: 8.882063\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 402: 8.875565\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 403: 8.870642\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 404: 8.869047\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 405: 8.872908\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 406: 8.872305\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 407: 8.867285\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 408: 8.864704\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 409: 8.870876\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 410: 8.881390\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 411: 8.875726\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 412: 8.869168\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 413: 8.875758\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 414: 8.874364\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 415: 8.868884\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 416: 8.893077\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 417: 8.871960\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 418: 8.872964\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 419: 8.868599\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 420: 8.876754\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 421: 8.866064\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 422: 8.873455\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 423: 8.866221\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 424: 8.866463\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 425: 8.869021\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 426: 8.871273\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 427: 8.864391\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 428: 8.880678\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 429: 8.879401\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 430: 8.883063\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 431: 8.871485\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 432: 8.875256\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 433: 8.873417\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 434: 8.870556\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 435: 8.882363\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 436: 8.867567\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 437: 8.866674\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 438: 8.870304\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 439: 8.871148\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 440: 8.869691\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 441: 8.872210\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 442: 8.862468\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 443: 8.867491\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 444: 8.870747\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 445: 8.870042\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 446: 8.866966\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 447: 8.872237\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 448: 8.870667\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 449: 8.866798\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 450: 8.870084\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 451: 8.869956\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 452: 8.881597\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 453: 8.865664\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 454: 8.867299\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 455: 8.866696\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 456: 8.867048\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 457: 8.874290\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 458: 8.872522\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 459: 8.873455\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 460: 8.873920\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 461: 8.870448\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 462: 8.867885\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 463: 8.867297\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 464: 8.872000\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 465: 8.870377\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 466: 8.870267\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 467: 8.862903\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 468: 8.862042\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 469: 8.874834\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 470: 8.868091\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 471: 8.866197\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 472: 8.872763\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 473: 8.866755\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 474: 8.874766\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 475: 8.872292\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 476: 8.872722\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 477: 8.875410\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 478: 8.863031\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 479: 8.869613\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 480: 8.865616\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 481: 8.876716\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 482: 8.873142\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 483: 8.869403\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 484: 8.872607\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 485: 8.870097\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 486: 8.865993\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 487: 8.862782\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 488: 8.875546\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 489: 8.872517\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 490: 8.875688\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 491: 8.864432\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 492: 8.864320\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 493: 8.878995\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 494: 8.865253\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 495: 8.882351\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 496: 8.866405\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 497: 8.864258\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 498: 8.869867\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 499: 8.871529\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 500: 8.870094\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 501: 8.864608\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 502: 8.870554\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 503: 8.868168\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 504: 8.875841\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 505: 8.870716\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 506: 8.868408\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 507: 8.869355\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 508: 8.861447\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 509: 8.864215\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 510: 8.869739\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 511: 8.864281\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 512: 8.869248\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 513: 8.865815\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 514: 8.865846\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 515: 8.867827\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 516: 8.864482\n",
      "Validation accuracy: 89.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 517: 8.865342\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 518: 8.864526\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 519: 8.877947\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 520: 8.867218\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 521: 8.868224\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 522: 8.867181\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 523: 8.870403\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 524: 8.873435\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 525: 8.860965\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 526: 8.866869\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 527: 8.860522\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 528: 8.867268\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 529: 8.861529\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 530: 8.868606\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 531: 8.862040\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 532: 8.865863\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 533: 8.864073\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 534: 8.867629\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 535: 8.863447\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 536: 8.868641\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 537: 8.864049\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 538: 8.868228\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 539: 8.873598\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 540: 8.863962\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 541: 8.865241\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 542: 8.872037\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 543: 8.864716\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 544: 8.871183\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 545: 8.871990\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 546: 8.866919\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 547: 8.865133\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 548: 8.865668\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 549: 8.871179\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 550: 8.871492\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 551: 8.867908\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 552: 8.873519\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 553: 8.862501\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 554: 8.869482\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 555: 8.871019\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 556: 8.870251\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 557: 8.870159\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 558: 8.876575\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 559: 8.865179\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 560: 8.862515\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 561: 8.863679\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 562: 8.860987\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 563: 8.874685\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 564: 8.869949\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 565: 8.870543\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 566: 8.872203\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 567: 8.870263\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 568: 8.863521\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 569: 8.864124\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 570: 8.870022\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 571: 8.867493\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 572: 8.869508\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 573: 8.866724\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 574: 8.867639\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 575: 8.861108\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 576: 8.864991\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 577: 8.881189\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 578: 8.870771\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 579: 8.865843\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 580: 8.863905\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 581: 8.868194\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 582: 8.868344\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 583: 8.866236\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 584: 8.868398\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 585: 8.863279\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 586: 8.863399\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 587: 8.863854\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 588: 8.862939\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 589: 8.880803\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 590: 8.871356\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 591: 8.864354\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 592: 8.864080\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 593: 8.861033\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 594: 8.863187\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 595: 8.868079\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 596: 8.868178\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 597: 8.870248\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 598: 8.864440\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 599: 8.878078\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 600: 8.863821\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 601: 8.883654\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 602: 8.865850\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 603: 8.866569\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 604: 8.863685\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 605: 8.862327\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 606: 8.869595\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 607: 8.866892\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 608: 8.867787\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 609: 8.867756\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 610: 8.873942\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 611: 8.868163\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 612: 8.870117\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 613: 8.865617\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 614: 8.866489\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 615: 8.859991\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 616: 8.872799\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 617: 8.871663\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 618: 8.864448\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 619: 8.864652\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 620: 8.864636\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 621: 8.861914\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 622: 8.866761\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 623: 8.868683\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 624: 8.865808\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 625: 8.866223\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 626: 8.865180\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 627: 8.862954\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 628: 8.863621\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 629: 8.868490\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 630: 8.871069\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 631: 8.865173\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 632: 8.865869\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 633: 8.867150\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 634: 8.868047\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 635: 8.865432\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 636: 8.870580\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 637: 8.864836\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 638: 8.858610\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 639: 8.858522\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 640: 8.864264\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 641: 8.862994\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 642: 8.861871\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 643: 8.862242\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 644: 8.863051\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 645: 8.867724\n",
      "Validation accuracy: 89.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 646: 8.867437\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 647: 8.863062\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 648: 8.869162\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 649: 8.862691\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 650: 8.864006\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 651: 8.861938\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 652: 8.868344\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 653: 8.867041\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 654: 8.861537\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 655: 8.857241\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 656: 8.865775\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 657: 8.872579\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 658: 8.864996\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 659: 8.863495\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 660: 8.866700\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 661: 8.863105\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 662: 8.864855\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 663: 8.865910\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 664: 8.872813\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 665: 8.867658\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 666: 8.867592\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 667: 8.859734\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 668: 8.867178\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 669: 8.863347\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 670: 8.875228\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 671: 8.864924\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 672: 8.864224\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 673: 8.865435\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 674: 8.861496\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 675: 8.866517\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 676: 8.861776\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 677: 8.861053\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 678: 8.867547\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 679: 8.866809\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 680: 8.863287\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 681: 8.869452\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 682: 8.872754\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 683: 8.863086\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 684: 8.866210\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 685: 8.873246\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 686: 8.868487\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 687: 8.881155\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 688: 8.864992\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 689: 8.865534\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 690: 8.865719\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 691: 8.866923\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 692: 8.862506\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 693: 8.866276\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 694: 8.865356\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 695: 8.864556\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 696: 8.870092\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 697: 8.862383\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 698: 8.863823\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 699: 8.862788\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 700: 8.860404\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 701: 8.869414\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 702: 8.869791\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 703: 8.861460\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 704: 8.867818\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 705: 8.875497\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 706: 8.859855\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 707: 8.867222\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 708: 8.865169\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 709: 8.862876\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 710: 8.865858\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 711: 8.863294\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 712: 8.866293\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 713: 8.866691\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 714: 8.870603\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 715: 8.865466\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 716: 8.866099\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 717: 8.860860\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 718: 8.859248\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 719: 8.865247\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 720: 8.862372\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 721: 8.860646\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 722: 8.858976\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 723: 8.868992\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 724: 8.859832\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 725: 8.862327\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 726: 8.870682\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 727: 8.867770\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 728: 8.862062\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 729: 8.865035\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 730: 8.873353\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 731: 8.875793\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 732: 8.869860\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 733: 8.861163\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 734: 8.871125\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 735: 8.860723\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 736: 8.863528\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 737: 8.865403\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 738: 8.862608\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 739: 8.861539\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 740: 8.861841\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 741: 8.861116\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 742: 8.871430\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 743: 8.859997\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 744: 8.863140\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 745: 8.869115\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 746: 8.869474\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 747: 8.864403\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 748: 8.861307\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 749: 8.865545\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 750: 8.864852\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 751: 8.858008\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 752: 8.860167\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 753: 8.862413\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 754: 8.864514\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 755: 8.868691\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 756: 8.863074\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 757: 8.867291\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 758: 8.869088\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 759: 8.867682\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 760: 8.866867\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 761: 8.858368\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 762: 8.862183\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 763: 8.861307\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 764: 8.859822\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 765: 8.865839\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 766: 8.866478\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 767: 8.869142\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 768: 8.867989\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 769: 8.866119\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 770: 8.866186\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 771: 8.865192\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 772: 8.864467\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 773: 8.871642\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 774: 8.862277\n",
      "Validation accuracy: 89.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 775: 8.862507\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 776: 8.860339\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 777: 8.864556\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 778: 8.863983\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 779: 8.864160\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 780: 8.860457\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 781: 8.865002\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 782: 8.864102\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 783: 8.861045\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 784: 8.865319\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 785: 8.862155\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 786: 8.866470\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 787: 8.860773\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 788: 8.859975\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 789: 8.864376\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 790: 8.869871\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 791: 8.859849\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 792: 8.865637\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 793: 8.861173\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 794: 8.864998\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 795: 8.867586\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 796: 8.859810\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 797: 8.860629\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 798: 8.865997\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 799: 8.865765\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 800: 8.865238\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 801: 8.865114\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 802: 8.858700\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 803: 8.871053\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 804: 8.863057\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 805: 8.869821\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 806: 8.865049\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 807: 8.865232\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 808: 8.861516\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 809: 8.864990\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 810: 8.863884\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 811: 8.861308\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 812: 8.861962\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 813: 8.866400\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 814: 8.859012\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 815: 8.867303\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 816: 8.870233\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 817: 8.861108\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 818: 8.857728\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 819: 8.862887\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 820: 8.860418\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 821: 8.861115\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 822: 8.864858\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 823: 8.859389\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 824: 8.869971\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 825: 8.865700\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 826: 8.867287\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 827: 8.858665\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 828: 8.864558\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 829: 8.863417\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 830: 8.865760\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 831: 8.865922\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 832: 8.860009\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 833: 8.868870\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 834: 8.865860\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 835: 8.867787\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 836: 8.859954\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 837: 8.868638\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 838: 8.862463\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 839: 8.862958\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 840: 8.865362\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 841: 8.869424\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 842: 8.865936\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 843: 8.864743\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 844: 8.860519\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 845: 8.866369\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 846: 8.862483\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 847: 8.859290\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 848: 8.864438\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 849: 8.862132\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 850: 8.864136\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 851: 8.865967\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 852: 8.865390\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 853: 8.862955\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 854: 8.866959\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 855: 8.862529\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 856: 8.858808\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 857: 8.863375\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 858: 8.859590\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 859: 8.862370\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 860: 8.865186\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 861: 8.862394\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 862: 8.863892\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 863: 8.866279\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 864: 8.859879\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 865: 8.856247\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 866: 8.860968\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 867: 8.865180\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 868: 8.861438\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 869: 8.858823\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 870: 8.860202\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 871: 8.859387\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 872: 8.862150\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 873: 8.862285\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 874: 8.866396\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 875: 8.867411\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 876: 8.864137\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 877: 8.862819\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 878: 8.862923\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 879: 8.863784\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 880: 8.863725\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 881: 8.864999\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 882: 8.867635\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 883: 8.864174\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 884: 8.861030\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 885: 8.858393\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 886: 8.864105\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 887: 8.871670\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 888: 8.858432\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 889: 8.859781\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 890: 8.861625\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 891: 8.863970\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 892: 8.862626\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 893: 8.859964\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 894: 8.860426\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 895: 8.864465\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 896: 8.863077\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 897: 8.860287\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 898: 8.861346\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 899: 8.858935\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 900: 8.863190\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 901: 8.859846\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 902: 8.862362\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 903: 8.864526\n",
      "Validation accuracy: 89.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 904: 8.872505\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 905: 8.862423\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 906: 8.862557\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 907: 8.864525\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 908: 8.858666\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 909: 8.861141\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 910: 8.860847\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 911: 8.859454\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 912: 8.865905\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 913: 8.866002\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 914: 8.860545\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 915: 8.861952\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 916: 8.864741\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 917: 8.857831\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 918: 8.862714\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 919: 8.868084\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 920: 8.860465\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 921: 8.857365\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 922: 8.861172\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 923: 8.862630\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 924: 8.858733\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 925: 8.868521\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 926: 8.863329\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 927: 8.863292\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 928: 8.864208\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 929: 8.861259\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 930: 8.860992\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 931: 8.858214\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 932: 8.864524\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 933: 8.857308\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 934: 8.860012\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 935: 8.858756\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 936: 8.862799\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 937: 8.860503\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 938: 8.861400\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 939: 8.859402\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 940: 8.857554\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 941: 8.862130\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 942: 8.860612\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 943: 8.863371\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 944: 8.868543\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 945: 8.862120\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 946: 8.864678\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 947: 8.859388\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 948: 8.861375\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 949: 8.861435\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 950: 8.859116\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 951: 8.858755\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 952: 8.857534\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 953: 8.864042\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 954: 8.860938\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 955: 8.863271\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 956: 8.861505\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 957: 8.859002\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 958: 8.859279\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 959: 8.870066\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 960: 8.868590\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 961: 8.860550\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 962: 8.860452\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 963: 8.869983\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 964: 8.861588\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 965: 8.865399\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 966: 8.857597\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 967: 8.863417\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 968: 8.856356\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 969: 8.864820\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 970: 8.864936\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 971: 8.864260\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 972: 8.861899\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 973: 8.861093\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 974: 8.858125\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 975: 8.860792\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 976: 8.859395\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 977: 8.860778\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 978: 8.865390\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 979: 8.870735\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 980: 8.859354\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 981: 8.857651\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 982: 8.861273\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 983: 8.858016\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 984: 8.861871\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 985: 8.857161\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 986: 8.859252\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 987: 8.864018\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 988: 8.860023\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 989: 8.863399\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 990: 8.862069\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 991: 8.867167\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 992: 8.868807\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 993: 8.863837\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 994: 8.862210\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 995: 8.862593\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 996: 8.860357\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 997: 8.862664\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 998: 8.860726\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 999: 8.860186\n",
      "Validation accuracy: 89.3%\n",
      "Test accuracy: 89.4%\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.equal(np.argmax(predictions, 1), np.argmax(labels, 1)))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "batch_num = (int)(train_labels.shape[0]/batch_size)\n",
    "\n",
    "with tf.Session(graph=graph_gs, config=conf) as session_gs:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        random = np.random.permutation(train_labels.shape[0])\n",
    "        loss = 0\n",
    "        for b in range(batch_num):\n",
    "            batch_data = train_dataset[random[b*batch_size:(b+1)*batch_size]]\n",
    "            batch_labels = train_labels[random[b*batch_size:(b+1)*batch_size]].astype(float)\n",
    "            feed_dict_gs = {tf_dataset_gs: batch_data, tf_labels_gs: batch_labels, keep_prob:1, is_train:True}\n",
    "            _, l_gs, predictions_l = session_gs.run([optimizer_gs, loss_gs, prediction_gs], feed_dict=feed_dict_gs)\n",
    "            loss += l_gs\n",
    "        print(\"Minibatch loss at step %d: %f\" % (step, loss))\n",
    "        feed_dict_val_gs = {tf_dataset_gs: valid_dataset}\n",
    "        valid_prediction_gs = session_gs.run(prediction_gs, feed_dict={tf_dataset_gs: valid_dataset, tf_labels_gs: valid_labels, keep_prob:1, is_train: False})\n",
    "        print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction_gs, valid_labels))\n",
    "        \n",
    "    feed_dict_test_gs = {tf_dataset_gs: test_dataset, keep_prob:1.0, is_train: False}\n",
    "    test_prediction_gs = session_gs.run(prediction_gs, feed_dict=feed_dict_test_gs)\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction_gs, test_labels))\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(session_gs, \"./model_checkpoints/centralized_sample\"+str(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 52.5%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph_gs, config=conf) as session_gs:\n",
    "    tf.global_variables_initializer().run()\n",
    "    feed_dict_test_gs = {tf_dataset_gs: test_dataset, keep_prob:1}\n",
    "    test_prediction_gs = session_gs.run(prediction_gs, feed_dict=feed_dict_test_gs)\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction_gs, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
